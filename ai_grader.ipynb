{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Grader\n",
    "Use LLM to grade student answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai python-dotenv pandas openpyxl tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "# Load .env file\n",
    "dotenv.load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"gpt-35-turbo\"\n",
    "model_name = \"gpt-35-turbo\"\n",
    "base_folder = \"data/ITE3101_practical_tests/ite-3101-practical-test-ab-submissions/\"\n",
    "answer_excel = \"student_answer.xlsx\"\n",
    "answer_excel_path = base_folder + answer_excel\n",
    "standard_answer_path = base_folder + \"standard_answer_ab.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_answer_df = pd.read_excel(answer_excel_path)\n",
    "student_answer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_answer = pd.read_excel(standard_answer_path)\n",
    "standard_answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_answer_dict = standard_answer.set_index(\n",
    "    'Question Name').to_dict(orient='index')\n",
    "standard_answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "import json\n",
    "import langchain\n",
    "langchain.debug = False\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    model_name=model_name,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "\n",
    "def score_answer(instruction, starter, answer, mark, student_answer, student_commit):\n",
    "    template = \"You are a Python programming instructor who grades student Python exercises.\"\n",
    "    # load grader_prompt.txt\n",
    "    with open(\"grader_prompt.txt\") as f:\n",
    "        grader_prompt = f.read()\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", grader_prompt),\n",
    "    ])\n",
    "    # print(chat_prompt)\n",
    "    chain = chat_prompt | llm\n",
    "    data = {\"instruction\": instruction,\n",
    "            \"starter\": starter,\n",
    "            \"answer\": answer,\n",
    "            \"mark\": mark,\n",
    "            \"student_answer\": student_answer,\n",
    "            \"student_commit\": student_commit}\n",
    "\n",
    "    r = chain.invoke(data).content\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "rows = []\n",
    "for index, row in tqdm(student_answer_df.iterrows(), total=len(student_answer_df)):\n",
    "    for key, value in standard_answer_dict.items():\n",
    "        question = key\n",
    "        instruction = value[\"Instruction\"]\n",
    "        starter = value[\"Starter\"]\n",
    "        answer = value[\"Answer\"]\n",
    "        mark = value[\"Mark\"]\n",
    "        student_answer = row[key + \" Content\"]\n",
    "        student_commit = row[key + \" Commit\"]\n",
    "\n",
    "        for _ in range(3):  # Retry 3 times\n",
    "            try:\n",
    "                result = score_answer(\n",
    "                    instruction, starter, answer, mark, student_answer, student_commit)\n",
    "                result = json.loads(result)  # Parse the JSON response\n",
    "                break  # Break the loop if successful\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # Retry if JSON decoding error occurs\n",
    "\n",
    "        row[key + \" Score\"] = result[\"score\"]\n",
    "        row[key + \" Comments\"] = result[\"comments\"]\n",
    "        row[key + \" Calculation\"] = result[\"calculation\"]\n",
    "        row[key + \" Confident\"] = result[\"confident\"]\n",
    "\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = pd.DataFrame(rows)\n",
    "scored_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df[scored_df.filter(like='Score').columns] = scored_df.filter(\n",
    "    like='Score').astype(int)\n",
    "scored_df[scored_df.filter(like='Confident').columns] = scored_df.filter(\n",
    "    like='Confident').astype(int)\n",
    "scored_df[scored_df.filter(like='Commit').columns] = scored_df.filter(\n",
    "    like='Commit').astype(int)\n",
    "scored_df['total_score'] = scored_df.filter(like='Score').sum(axis=1)\n",
    "scored_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = scored_df.filter(like='Score').columns\n",
    "scored_df = scored_df[[\n",
    "    col for col in scored_df.columns if col not in score_columns] + list(score_columns)]\n",
    "scored_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = os.path.join(base_folder, 'student_score.xlsx')\n",
    "scored_df.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
